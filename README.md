# 样例

## 第一章样例

### 摘要

在这一章中我们提出了基于语音相关视觉特征的视觉辅助语音分离模型，旨在解决鸡尾酒会问题。该模型在四个音视频数据集上 (包括, GRID, TCD-TIMIT, LRS2, AVSpeech) 优于之前所有的视觉辅助语音分离模型，并且在真实复杂听觉场景下取得了令人惊艳的结果。

### 我们提出的模型

整个模型的框架如下图所示，详细设计细节及思路见论文。首先，利用人脸检测和人脸跟踪算法获得场景中/混合语音中说话人的数目并得到每个说话人的人脸缩略图；然后，由视觉编码器提取语音相关的视觉特征，语音编码器提取混合语音声学特征；最后，视觉辅助语音分离网络输入被关注说话人的语音相关视觉特征和混合语音声学特征后，输出被关注说话人的语音。


### 分离样例

#### 样例1

用于测试的模型在AVSpeech数据集 (中文仅占1%左右) 上训练得到，用于测试的视频从中文视频网上获取，且在语音分离任务最困难的情况下测试，即干扰说话人和目标说话人均为男生。结果显示，由我们模型分离得到的语音在听感和语音识别性能上都得到了大幅度的提升。此外，模型表现出非特定说话人，非特定语种的性质，即不依赖于说话人且不依赖于语种。
